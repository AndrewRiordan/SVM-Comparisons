{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('voice.csv')\n",
    "#add a bias term\n",
    "data['dummy'] = 1\n",
    "data['label'].replace({'male': -1, 'female': 1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diagnosis.csv')\n",
    "diagnosis_map = {'M':1, 'B':-1}\n",
    "data['diagnosis'] = data['diagnosis'].map(diagnosis_map)\n",
    "    # drop last column (extra column added by pd)\n",
    "    # and unnecessary first column (id)\n",
    "data.drop(data.columns[[-1, 0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.254833</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.967836</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
       "mean    -0.254833    14.127292     19.289649       91.969033   654.889104   \n",
       "std      0.967836     3.524049      4.301036       24.298981   351.914129   \n",
       "min     -1.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%     -1.000000    11.700000     16.170000       75.170000   420.300000   \n",
       "50%     -1.000000    13.370000     18.840000       86.240000   551.100000   \n",
       "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.pop('diagnosis')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 213.12, NNZs: 30, Bias: -15.753490, T: 569, Avg. loss: 3.950173\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 205.56, NNZs: 30, Bias: -13.084217, T: 1138, Avg. loss: 2.698267\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 196.02, NNZs: 30, Bias: -9.577350, T: 1707, Avg. loss: 2.037560\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 187.36, NNZs: 29, Bias: -18.481748, T: 2276, Avg. loss: 1.315070\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 184.82, NNZs: 30, Bias: -7.321369, T: 2845, Avg. loss: 1.286804\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.92, NNZs: 29, Bias: 0.187068, T: 3414, Avg. loss: 1.058924\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 181.25, NNZs: 30, Bias: 0.096752, T: 3983, Avg. loss: 1.076992\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 179.30, NNZs: 30, Bias: 0.255510, T: 4552, Avg. loss: 0.931580\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 176.77, NNZs: 30, Bias: 5.462318, T: 5121, Avg. loss: 0.945110\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 174.51, NNZs: 28, Bias: 5.428469, T: 5690, Avg. loss: 0.761469\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 172.40, NNZs: 30, Bias: 5.296686, T: 6259, Avg. loss: 0.642753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 171.02, NNZs: 27, Bias: 6.632657, T: 6828, Avg. loss: 0.648535\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 169.20, NNZs: 28, Bias: 6.583690, T: 7397, Avg. loss: 0.614720\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 168.12, NNZs: 28, Bias: 4.223654, T: 7966, Avg. loss: 0.506204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 167.13, NNZs: 27, Bias: 8.513523, T: 8535, Avg. loss: 0.549264\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 166.28, NNZs: 30, Bias: 6.542062, T: 9104, Avg. loss: 0.594915\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 165.44, NNZs: 30, Bias: 8.522865, T: 9673, Avg. loss: 0.487299\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 165.23, NNZs: 30, Bias: 8.573442, T: 10242, Avg. loss: 0.454538\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 164.30, NNZs: 30, Bias: 8.528632, T: 10811, Avg. loss: 0.479691\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 163.86, NNZs: 29, Bias: 8.525715, T: 11380, Avg. loss: 0.393968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 163.43, NNZs: 28, Bias: 7.747397, T: 11949, Avg. loss: 0.308213\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 162.87, NNZs: 28, Bias: 9.272078, T: 12518, Avg. loss: 0.399111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 162.30, NNZs: 28, Bias: 9.283294, T: 13087, Avg. loss: 0.332350\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 161.70, NNZs: 28, Bias: 10.695822, T: 13656, Avg. loss: 0.307402\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 161.42, NNZs: 28, Bias: 9.338423, T: 14225, Avg. loss: 0.304340\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 160.88, NNZs: 28, Bias: 10.026147, T: 14794, Avg. loss: 0.286200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 160.55, NNZs: 28, Bias: 9.409281, T: 15363, Avg. loss: 0.257684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 160.38, NNZs: 28, Bias: 10.589521, T: 15932, Avg. loss: 0.339075\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 160.09, NNZs: 28, Bias: 9.427990, T: 16501, Avg. loss: 0.287449\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 159.75, NNZs: 28, Bias: 9.996451, T: 17070, Avg. loss: 0.317832\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 159.37, NNZs: 28, Bias: 10.545508, T: 17639, Avg. loss: 0.290897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 159.09, NNZs: 28, Bias: 11.096050, T: 18208, Avg. loss: 0.287757\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 32 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -6.77851712, -11.77853582,  -6.60712608,   0.        ,\n",
       "          5.38265254, -33.12238133,  11.81327368,  11.89056086,\n",
       "        -21.11657644,   0.        ,  41.01936933, -11.48877948,\n",
       "         29.66271787,  48.51497814,  13.05666505,  -4.79571763,\n",
       "        -29.04645266,  26.75519655,  -2.23436307, -38.95607758,\n",
       "         28.68538352,  51.5992605 ,  18.61010985,  32.77830855,\n",
       "          8.30173059,  -7.08438609,  49.33876342,  30.98345267,\n",
       "         26.2977641 ,  19.26988932]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l1\", max_iter=400000000,verbose=True)\n",
    "clf.fit(X_train, y)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tried to establish a baseline for correctness but it doesn't look like the svm if converging\n",
    "#for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primal_score_l1(X,y,w,C):\n",
    "    score = w.dot(w) * .5\n",
    "    for i in range(X.shape[0]):\n",
    "        score += C * max((1-(y[i] * (w.dot(X[i]))),0))\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def dual_coord_l1(X, y, max_steps, C=.25):\n",
    "    u=C\n",
    "    n_features = X.shape[1]\n",
    "    n_samples = X.shape[0]\n",
    "    w = np.zeros(n_features)\n",
    "    alpha = np.zeros(n_samples)\n",
    "    for o in range(max_steps) : #outer iteration\n",
    "        for i in range(X.shape[0]): #inner iteration\n",
    "            #step a\n",
    "            G = y[i]*w.dot(X[i])-1+alpha[i] * 0 #G = yiwT xi − 1 + Diiαi\n",
    "            #step b of algorithm 1\n",
    "            PG = G \n",
    "            if (alpha[i]==0):\n",
    "                PG = min(G,0)\n",
    "            if (alpha[i]==u):\n",
    "                PG = max(G,0)\n",
    "            #step c\n",
    "            if PG != 0: \n",
    "                ahat = alpha[i]\n",
    "                alpha[i] = min(max(alpha[i]-G*((y[i]**2)*X[i].dot(X[i])),0),u)\n",
    "                w = w + ((alpha[i]-ahat)*y[i])*X[i]\n",
    "        if o % 100 == 0:\n",
    "            print(primal_score_l1(X,y,w,C))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.409126913337673\n",
      "33.712717403824705\n",
      "32.68653217196296\n",
      "21.50628035479923\n",
      "34.273858581761615\n",
      "31.012765899604965\n",
      "22.449479349261093\n",
      "24.031873826389766\n",
      "30.95067615585902\n",
      "24.834504968508096\n",
      "20.401285785391853\n",
      "32.54373652666618\n",
      "20.395892381342232\n",
      "27.967964455829886\n",
      "29.83389345279\n",
      "34.90007627995721\n",
      "31.326282482963347\n",
      "62.16457912488201\n",
      "32.461007704541196\n",
      "35.61733318840045\n",
      "32.87031889597017\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8z/r78hlgg53hndvvyjqvlsz3pw0000gn/T/ipykernel_16674/1626406422.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#are we supposed to guaruntee descent?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdual_coord_l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/8z/r78hlgg53hndvvyjqvlsz3pw0000gn/T/ipykernel_16674/2641205787.py\u001b[0m in \u001b[0;36mdual_coord_l1\u001b[0;34m(X, y, max_steps, C)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#inner iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m#step a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#G = yiwT xi − 1 + Diiαi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m#step b of algorithm 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mPG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_1tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#are we supposed to guaruntee descent?\n",
    "\n",
    "print(dual_coord_l1(X_train,y,9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://github.com/qandeelabbassi/python-svm-sgd/blob/master/svm.py\n",
    "from sklearn.utils import shuffle\n",
    "regularization_strength = 10000\n",
    "learning_rate = 0.000001\n",
    "def compute_cost(W, X, Y):\n",
    "    # calculate hinge loss\n",
    "    N = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge_loss = regularization_strength * (np.sum(distances) / N)\n",
    "\n",
    "    # calculate cost\n",
    "    cost = (1 / 2) * np.dot(W, W) + hinge_loss\n",
    "    return cost\n",
    "\n",
    "\n",
    "# I haven't tested it but this same function should work for\n",
    "# vanilla and mini-batch gradient descent as well\n",
    "def calculate_cost_gradient(W, X_batch, Y_batch):\n",
    "    # if only one example is passed (eg. in case of SGD)\n",
    "    if type(Y_batch) == np.float64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])  # gives multidimensional array\n",
    "\n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "    \n",
    "    #for ind, d in enumerate(distance):\n",
    "    if max(0, distance) == 0:\n",
    "        di = W\n",
    "    else:\n",
    "        di = W - (regularization_strength * Y_batch * X_batch)\n",
    "    dw += di\n",
    "   # average\n",
    "    return dw\n",
    "\n",
    "\n",
    "def sgd(features, outputs):\n",
    "    max_epochs = 5000\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    nth = 0\n",
    "    prev_cost = float(\"inf\")\n",
    "    cost_threshold = 0.01  # in percent\n",
    "    # stochastic gradient descent\n",
    "    for epoch in range(1, max_epochs):\n",
    "        # shuffle to prevent repeating update cycles\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        for ind, x in enumerate(X):\n",
    "            ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
    "            weights = weights - (learning_rate * ascent)\n",
    "\n",
    "        # convergence check on 2^nth epoch\n",
    "        if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "            cost = compute_cost(weights, features, outputs)\n",
    "            print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
    "            # stoppage criterion\n",
    "            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                return weights\n",
    "            prev_cost = cost\n",
    "            nth += 1\n",
    "    return weights\n",
    "\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1 and Cost is: 0.2455319229993855\n",
      "Epoch is: 2 and Cost is: 0.35524854662200356\n",
      "Epoch is: 4 and Cost is: 0.19277747620255886\n",
      "Epoch is: 8 and Cost is: 0.22409566899219346\n",
      "Epoch is: 16 and Cost is: 0.22526098109371293\n",
      "Epoch is: 32 and Cost is: 0.2198822015413781\n",
      "Epoch is: 64 and Cost is: 0.25878653028981063\n",
      "Epoch is: 128 and Cost is: 0.16937431462228394\n",
      "Epoch is: 256 and Cost is: 0.3269824865812569\n",
      "Epoch is: 512 and Cost is: 0.33000514815263393\n",
      "Epoch is: 1024 and Cost is: 0.29787584642805987\n",
      "Epoch is: 2048 and Cost is: 0.36297588131395625\n",
      "Epoch is: 4096 and Cost is: 0.24988135873044506\n",
      "Epoch is: 4999 and Cost is: 0.17529462886818137\n",
      "[ 0.04413928 -0.04852807  0.04341001  0.04179818  0.03433026  0.02996103\n",
      "  0.03279374  0.04696337  0.03412655  0.00166379  0.03305609 -0.05357364\n",
      "  0.02782375  0.03259848 -0.05744366 -0.01533066 -0.00226759 -0.00252357\n",
      "  0.00211147 -0.01797298  0.04378565 -0.03647993  0.04380527  0.0417548\n",
      "  0.02392239  0.01838446  0.026981    0.04491856  0.05064753  0.01025409]\n"
     ]
    }
   ],
   "source": [
    "print(sgd(X_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4923.070396598613\n"
     ]
    }
   ],
   "source": [
    "print(primal_score_l1(X_train,y,clf.coef_[0],.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.391448368223829\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "sf = svm.SVC(kernel=\"linear\", C=.25)\n",
    "sf.fit(X_train,y)\n",
    "sf.coef_\n",
    "print(primal_score_l1(X_train,y,sf.coef_[0],.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1 and Cost is: 0.3466690697051721\n",
      "Epoch is: 2 and Cost is: 0.2578413980113502\n",
      "Epoch is: 4 and Cost is: 0.2915689623388304\n",
      "Epoch is: 8 and Cost is: 0.1498249781322012\n",
      "Epoch is: 16 and Cost is: 0.24489953831584638\n",
      "Epoch is: 32 and Cost is: 0.19184853178955852\n",
      "Epoch is: 64 and Cost is: 0.23852011864285252\n",
      "Epoch is: 128 and Cost is: 0.3003335495069751\n",
      "Epoch is: 256 and Cost is: 0.3406745591504034\n",
      "Epoch is: 512 and Cost is: 0.3080694321577936\n",
      "Epoch is: 1024 and Cost is: 0.27153753039788164\n",
      "Epoch is: 2048 and Cost is: 0.3074711069408479\n",
      "Epoch is: 4096 and Cost is: 0.14067255906734527\n",
      "Epoch is: 4999 and Cost is: 0.24014929087596731\n",
      "130.67793332056775\n"
     ]
    }
   ],
   "source": [
    "print(primal_score_l1(X_train,y,sgd(X_train, y),.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
